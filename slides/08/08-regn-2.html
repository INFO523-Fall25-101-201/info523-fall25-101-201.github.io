<!DOCTYPE html>
<html lang="en"><head>
<link href="../..//images/logo.png" rel="icon" type="image/png">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.33">

  <title>INFO 523 – Regressions II</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-191024931916078fc4eae1dde1f53f1c.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<meta property="og:title" content="Regressions II – INFO 523">
<meta property="og:description" content="Data Mining and Discovery">
<meta property="og:site_name" content="INFO 523">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="../minedata-bg.png" data-background-size="600px, cover" data-slide-number="none" class="quarto-title-block center">
  <h1 class="title">Regressions II</h1>
  <p class="subtitle">Data Mining and Discovery</p>

<div class="quarto-title-authors">
</div>

</section>
<section id="setup" class="slide level2 smaller">
<h2>Setup</h2>
<div id="setup" class="cell" data-message="false" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="co"># Import all required libraries</span></span>
<span id="cb1-2"><a></a><span class="co"># Data handling and manipulation</span></span>
<span id="cb1-3"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a></a></span>
<span id="cb1-6"><a></a><span class="co"># Implementing and selecting models</span></span>
<span id="cb1-7"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-8"><a></a><span class="im">from</span> itertools <span class="im">import</span> combinations</span>
<span id="cb1-9"><a></a><span class="im">from</span> mlxtend.feature_selection <span class="im">import</span> SequentialFeatureSelector <span class="im">as</span> SFS</span>
<span id="cb1-10"><a></a><span class="im">from</span> statsmodels.stats.outliers_influence <span class="im">import</span> variance_inflation_factor</span>
<span id="cb1-11"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, cross_val_score, KFold</span>
<span id="cb1-12"><a></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV, LinearRegression</span>
<span id="cb1-13"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score</span>
<span id="cb1-14"><a></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-15"><a></a><span class="im">from</span> sklearn.cross_decomposition <span class="im">import</span> PLSRegression</span>
<span id="cb1-16"><a></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-17"><a></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-18"><a></a></span>
<span id="cb1-19"><a></a><span class="co"># For advanced visualizations</span></span>
<span id="cb1-20"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-21"><a></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-22"><a></a></span>
<span id="cb1-23"><a></a><span class="co"># Show computation time</span></span>
<span id="cb1-24"><a></a><span class="im">import</span> time</span>
<span id="cb1-25"><a></a></span>
<span id="cb1-26"><a></a><span class="co"># Increase font size of all Seaborn plot elements</span></span>
<span id="cb1-27"><a></a>sns.<span class="bu">set</span>(font_scale <span class="op">=</span> <span class="fl">1.25</span>)</span>
<span id="cb1-28"><a></a></span>
<span id="cb1-29"><a></a><span class="co"># Set Seaborn theme</span></span>
<span id="cb1-30"><a></a>sns.set_theme(style <span class="op">=</span> <span class="st">"white"</span>, palette <span class="op">=</span> <span class="st">"colorblind"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section>
<section id="regressions-ii" class="title-slide slide level1 center">
<h1>Regressions II</h1>

</section>
<section id="our-data-indoor-air-pollution" class="slide level2 smaller">
<h2>Our data: Indoor air pollution</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Read + head</a></li><li><a href="#tabset-1-2">Metadata</a></li><li><a href="#tabset-1-3">Info</a></li><li><a href="#tabset-1-4">Describe</a></li><li><a href="#tabset-1-5">Missing values</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<div id="17a9fd52" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="im">import</span> janitor</span>
<span id="cb2-2"><a></a></span>
<span id="cb2-3"><a></a>pollution <span class="op">=</span> pd.read_csv(<span class="st">"data/merged_pollution.csv"</span>, encoding <span class="op">=</span> <span class="st">'iso-8859-1'</span>)</span>
<span id="cb2-4"><a></a>pollution <span class="op">=</span> janitor.clean_names(pollution)</span>
<span id="cb2-5"><a></a></span>
<span id="cb2-6"><a></a>pollution.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">entity</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">access_clean_perc</th>
<th data-quarto-table-cell-role="th">gdp</th>
<th data-quarto-table-cell-role="th">popn</th>
<th data-quarto-table-cell-role="th">death_rate_asp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>2000.0</td>
<td>-1.371886</td>
<td>0.000000</td>
<td>-0.104197</td>
<td>371.951345</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>2001.0</td>
<td>-1.353313</td>
<td>0.000000</td>
<td>-0.102565</td>
<td>368.490253</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>2002.0</td>
<td>-1.330292</td>
<td>-0.877632</td>
<td>-0.100603</td>
<td>355.870851</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>2003.0</td>
<td>-1.302300</td>
<td>-0.875238</td>
<td>-0.098471</td>
<td>350.188748</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0</td>
<td>2004.0</td>
<td>-1.276925</td>
<td>-0.877087</td>
<td>-0.096407</td>
<td>341.858106</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="tabset-1-2">
<table class="caption-top">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><strong>variable</strong></th>
<th><strong>class</strong></th>
<th><strong>description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>entity</td>
<td>character</td>
<td>Country, unique number identifier</td>
</tr>
<tr class="even">
<td>year</td>
<td>double</td>
<td>Year</td>
</tr>
<tr class="odd">
<td>access_clean_perc</td>
<td>double</td>
<td>% of population with access to clean cooking fuels</td>
</tr>
<tr class="even">
<td>gdp</td>
<td>double</td>
<td>GDP per capita, PPP (constant 2017 international $)</td>
</tr>
<tr class="odd">
<td>popn</td>
<td>character</td>
<td>Country population</td>
</tr>
<tr class="even">
<td>death_rate_asp</td>
<td>double</td>
<td>Cause of death related to air pollution from solid fuels, standardized</td>
</tr>
</tbody>
</table>
</div>
<div id="tabset-1-3">
<div id="41d77fa1" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>pollution.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 3264 entries, 0 to 3263
Data columns (total 6 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   entity             3264 non-null   int64  
 1   year               3264 non-null   float64
 2   access_clean_perc  3264 non-null   float64
 3   gdp                3264 non-null   float64
 4   popn               3264 non-null   float64
 5   death_rate_asp     3264 non-null   float64
dtypes: float64(5), int64(1)
memory usage: 153.1 KB</code></pre>
</div>
</div>
</div>
<div id="tabset-1-4">
<div id="ebb32f58" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a>pollution.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">entity</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">access_clean_perc</th>
<th data-quarto-table-cell-role="th">gdp</th>
<th data-quarto-table-cell-role="th">popn</th>
<th data-quarto-table-cell-role="th">death_rate_asp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>3264.000000</td>
<td>3264.00000</td>
<td>3.264000e+03</td>
<td>3.264000e+03</td>
<td>3.264000e+03</td>
<td>3264.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>95.500000</td>
<td>2008.00000</td>
<td>-1.349683e-16</td>
<td>8.707632e-18</td>
<td>4.353816e-17</td>
<td>70.587846</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>55.433366</td>
<td>4.89973</td>
<td>1.000153e+00</td>
<td>1.000153e+00</td>
<td>1.000153e+00</td>
<td>87.057969</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>0.000000</td>
<td>2000.00000</td>
<td>-1.598171e+00</td>
<td>-9.067143e-01</td>
<td>-1.451953e-01</td>
<td>0.005738</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>47.750000</td>
<td>2004.00000</td>
<td>-1.064244e+00</td>
<td>-7.425174e-01</td>
<td>-1.417803e-01</td>
<td>1.090309</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>95.500000</td>
<td>2008.00000</td>
<td>4.424448e-01</td>
<td>-3.377230e-01</td>
<td>-1.295730e-01</td>
<td>23.828597</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>143.250000</td>
<td>2012.00000</td>
<td>9.444564e-01</td>
<td>3.119429e-01</td>
<td>-9.508658e-02</td>
<td>135.902705</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>191.000000</td>
<td>2016.00000</td>
<td>1.013911e+00</td>
<td>5.036683e+00</td>
<td>1.458832e+01</td>
<td>474.973060</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="tabset-1-5">
<div id="8dd78c07" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a>pollution.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>entity               0
year                 0
access_clean_perc    0
gdp                  0
popn                 0
death_rate_asp       0
dtype: int64</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="multiple-regression" class="slide level2">
<h2>Multiple regression</h2>
<div id="07abaaa3" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a><span class="co"># Assuming pollution DataFrame is predefined</span></span>
<span id="cb8-2"><a></a>X <span class="op">=</span> pollution[[<span class="st">'year'</span>, <span class="st">'access_clean_perc'</span>, <span class="st">'gdp'</span>, <span class="st">'popn'</span>]]</span>
<span id="cb8-3"><a></a>y <span class="op">=</span> pollution[<span class="st">'death_rate_asp'</span>]</span>
<span id="cb8-4"><a></a></span>
<span id="cb8-5"><a></a><span class="co"># Train-test split</span></span>
<span id="cb8-6"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb8-7"><a></a></span>
<span id="cb8-8"><a></a><span class="co"># Adding a constant for OLS</span></span>
<span id="cb8-9"><a></a>X_train_with_const <span class="op">=</span> sm.add_constant(X_train)</span>
<span id="cb8-10"><a></a>X_test_with_const <span class="op">=</span> sm.add_constant(X_test)</span>
<span id="cb8-11"><a></a></span>
<span id="cb8-12"><a></a><span class="co"># Fitting the OLS model</span></span>
<span id="cb8-13"><a></a>model <span class="op">=</span> sm.OLS(y_train, X_train_with_const).fit()</span>
<span id="cb8-14"><a></a></span>
<span id="cb8-15"><a></a><span class="co"># Making predictions</span></span>
<span id="cb8-16"><a></a>y_pred <span class="op">=</span> model.predict(X_test_with_const)</span>
<span id="cb8-17"><a></a></span>
<span id="cb8-18"><a></a><span class="co"># Calculating MSE</span></span>
<span id="cb8-19"><a></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb8-20"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb8-21"><a></a></span>
<span id="cb8-22"><a></a><span class="co"># Extracting Adjusted R-squared from the model's summary</span></span>
<span id="cb8-23"><a></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb8-24"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared: </span><span class="sc">{</span>r2<span class="sc">:.4f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 1526.64
R-squared: 0.8002</code></pre>
</div>
</div>
</section>
<section id="regularization" class="slide level2">
<h2>Regularization</h2>
<blockquote>
<p>A technique used in regression to avoid <strong>overfitting</strong> by shrinking the coefficient estimates to 0.</p>
</blockquote>
<p><strong>Two main methods:</strong></p>
<ol type="1">
<li class="fragment"><p><strong>Ridge Regression</strong></p></li>
<li class="fragment"><p><strong>Lasso Regression</strong></p></li>
<li class="fragment"><p>…but also note cross-validation for hyperparameter tuning</p></li>
</ol>
</section>
<section id="ridge-regression" class="slide level2 smaller">
<h2>Ridge regression</h2>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">Visual</a></li><li><a href="#tabset-2-2">Variance inflation factor</a></li><li><a href="#tabset-2-3">Formula</a></li><li><a href="#tabset-2-4">Key points</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<div class="columns">
<div class="column" style="width:65%;">
<p><img data-src="images/ridge-1.png"></p>
</div><div class="column" style="width:35%;">
<p><br></p>
<p><img data-src="images/ridge-2.png" width="242"></p>
</div></div>
</div>
<div id="tabset-2-2">
<ul>
<li class="fragment"><p>VIF quantifies multicollinearity in OLS regressions</p></li>
<li class="fragment"><p>Assesses how much variation is increased by multicollinearity</p></li>
<li class="fragment"><p>High VIF indicated that predictor variables can be linearly predicted by each other</p></li>
</ul>
<h4 id="formula">Formula</h4>
<p><span class="math inline">\(VIF_j = \frac{1}{1-R^{2}_j}\)</span></p>
<ul>
<li class="fragment"><p><span class="math inline">\(VIF_j\)</span> is the Variance Inflation Factor for the <span class="math inline">\(j^{th}\)</span> predictor variable.</p></li>
<li class="fragment"><p><span class="math inline">\(R^{2}_j\)</span> is the coefficient of determination obtained by regressing the <span class="math inline">\(j^{th}\)</span> predictor variable against all other predictor variables.</p></li>
<li class="fragment"><p>Ranges from 1-5 (or 10)</p></li>
</ul>
</div>
<div id="tabset-2-3">
<p><span class="math inline">\(RSS + \lambda \sum_{j=1}^{p} \beta_j^2\)</span></p>
<ul>
<li class="fragment"><p>Where <span class="math inline">\(j\)</span> ranges from 1 to <span class="math inline">\(p\)</span> and <span class="math inline">\(\lambda \geq 0\)</span></p></li>
<li class="fragment"><p><span class="math inline">\(\sum_{j=1}^{p} \beta_j^2\)</span> is the L2 normalization term</p></li>
</ul>
</div>
<div id="tabset-2-4">
<ul>
<li class="fragment"><p><strong>Penalized Regression</strong>: Adds a penalty to OLS to regularize coefficients, aiding in handling multicollinearity and reducing complexity.</p></li>
<li class="fragment"><p><strong>Coefficient Shrinkage</strong>: Coefficients shrink towards zero, enhancing stability and accuracy.</p></li>
<li class="fragment"><p><strong>L2 Regularization</strong>: Employs squared coefficient sum as a penalty, regulated by <span class="math inline">\(\lambda\)</span>.</p></li>
<li class="fragment"><p><strong>Bias-Variance Trade-off</strong>: Slightly increases bias to reduce variance, preventing overfitting.</p></li>
<li class="fragment"><p><strong>Efficient Computation</strong>: Features a closed-form solution, ensuring computational efficiency.</p></li>
<li class="fragment"><p><strong>No Feature Elimination</strong>: Maintains all features due to non-zero coefficients, unlike Lasso.</p></li>
<li class="fragment"><p><strong>Effective in</strong> <span class="math inline">\(p &gt; n\)</span>: Remains effective when predictors outnumber observations.</p></li>
<li class="fragment"><p><strong>Interpretability</strong>: Less interpretable because all predictors are included.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="investigate-vif" class="slide level2">
<h2>Investigate VIF</h2>
<div id="c2c63e20" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>VIFs <span class="op">=</span> [variance_inflation_factor(X.values, i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>])]</span>
<span id="cb10-2"><a></a><span class="cf">for</span> idx, vif <span class="kw">in</span> <span class="bu">enumerate</span>(VIFs):</span>
<span id="cb10-3"><a></a>    <span class="bu">print</span>(<span class="ss">f"VIF for column </span><span class="sc">{</span>X<span class="sc">.</span>columns[idx]<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>vif<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>VIF for column year: 1.000000034024503
VIF for column access_clean_perc: 1.6782080674029214
VIF for column gdp: 1.6785951365989462
VIF for column popn: 1.0005167748859174</code></pre>
</div>
</div>
<ul>
<li class="fragment"><p><code>Entity</code> and <code>Year</code> have relatively high VIF</p></li>
<li class="fragment"><p>Remaining columns relatively low VIF</p></li>
</ul>
</section>
<section id="ridge-regression-applied" class="slide level2 smaller">
<h2>Ridge regression: applied</h2>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">Model summary</a></li><li><a href="#tabset-3-2">Residual plot</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<div id="f0b53736" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb12-2"><a></a></span>
<span id="cb12-3"><a></a><span class="co"># Add a constant to the model (for statsmodels)</span></span>
<span id="cb12-4"><a></a>X_train_const <span class="op">=</span> sm.add_constant(X_train)</span>
<span id="cb12-5"><a></a>X_test_const <span class="op">=</span> sm.add_constant(X_test)</span>
<span id="cb12-6"><a></a></span>
<span id="cb12-7"><a></a><span class="co"># Initialize the Ridge Regression model</span></span>
<span id="cb12-8"><a></a>ridge_reg <span class="op">=</span> Ridge(alpha <span class="op">=</span> <span class="dv">1</span>)  <span class="co"># Alpha is the regularization strength; adjust accordingly</span></span>
<span id="cb12-9"><a></a></span>
<span id="cb12-10"><a></a><span class="co"># Fit the model</span></span>
<span id="cb12-11"><a></a>ridge_reg.fit(X_train, y_train)</span>
<span id="cb12-12"><a></a></span>
<span id="cb12-13"><a></a><span class="co"># Predict on the testing set</span></span>
<span id="cb12-14"><a></a>y_pred <span class="op">=</span> ridge_reg.predict(X_test)</span>
<span id="cb12-15"><a></a></span>
<span id="cb12-16"><a></a><span class="co"># Calculate and print the MSE</span></span>
<span id="cb12-17"><a></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb12-18"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb12-19"><a></a></span>
<span id="cb12-20"><a></a><span class="co"># Since Ridge doesn't provide AIC, BIC directly, we focus on what's available</span></span>
<span id="cb12-21"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared: </span><span class="sc">{</span>r2<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 1526.7075294439708

R-squared: 0.8002256325350543</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2">
<div id="368fd218" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_pred</span>
<span id="cb14-2"><a></a>sns.residplot(x <span class="op">=</span> y_pred, y <span class="op">=</span> residuals, lowess <span class="op">=</span> <span class="va">True</span>, line_kws <span class="op">=</span> {<span class="st">'color'</span>: <span class="st">'red'</span>, <span class="st">'lw'</span>: <span class="dv">1</span>})</span>
<span id="cb14-3"><a></a>plt.xlabel(<span class="st">'Predicted Values'</span>)</span>
<span id="cb14-4"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb14-5"><a></a>plt.title(<span class="st">'Residual Plot'</span>)</span>
<span id="cb14-6"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-10-output-1.png" width="832" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="model-tuning" class="slide level2 smaller">
<h2>Model tuning</h2>
<blockquote>
<p>Optimizing the hyperparameters of a machine learning model to enhance its performance. The process aims to find the best combination of hyperparameters that results in the most accurate predictions for a given dataset.</p>
</blockquote>
<p><strong>Key points:</strong></p>
<ul>
<li class="fragment"><p><strong>Hyperparameters</strong>: Pre-set parameters influencing model behavior, not derived from data.</p></li>
<li class="fragment"><p><strong>Search Methods</strong>: Techniques like Grid Search and Random Search to explore hyperparameter spaces.</p></li>
<li class="fragment"><p><strong>Cross-Validation</strong>: Essential for assessing model generalizability during tuning.</p></li>
<li class="fragment"><p><strong>Performance Metrics</strong>: Criteria like accuracy or MSE to evaluate hyperparameter efficacy.</p></li>
<li class="fragment"><p><strong>Computational Cost</strong>: Potentially high, depending on hyperparameter space complexity.</p></li>
</ul>
</section>
<section id="model-tuning-ridge-regression" class="slide level2 smaller">
<h2>Model tuning: Ridge regression</h2>
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-4-1">Applied</a></li><li><a href="#tabset-4-2">Re-evaluate model</a></li><li><a href="#tabset-4-3">Compare with previous model</a></li><li><a href="#tabset-4-4">Residuals</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1">
<div id="ab46a765" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="co"># Define a set of alpha values</span></span>
<span id="cb15-2"><a></a>alphas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">13</span>)</span>
<span id="cb15-3"><a></a></span>
<span id="cb15-4"><a></a><span class="co"># Initialize RidgeCV</span></span>
<span id="cb15-5"><a></a>ridge_cv <span class="op">=</span> RidgeCV(alphas <span class="op">=</span> alphas, store_cv_results <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb15-6"><a></a></span>
<span id="cb15-7"><a></a><span class="co"># Fit the model</span></span>
<span id="cb15-8"><a></a>ridge_cv.fit(X_train, y_train)</span>
<span id="cb15-9"><a></a></span>
<span id="cb15-10"><a></a><span class="co"># Best alpha value</span></span>
<span id="cb15-11"><a></a><span class="bu">print</span>(<span class="ss">f'Best alpha: </span><span class="sc">{</span>ridge_cv<span class="sc">.</span>alpha_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb15-12"><a></a></span>
<span id="cb15-13"><a></a><span class="co"># Re-initialize and fit the model with the best alpha</span></span>
<span id="cb15-14"><a></a>best_ridge <span class="op">=</span> Ridge(alpha <span class="op">=</span> ridge_cv.alpha_)</span>
<span id="cb15-15"><a></a>best_ridge.fit(X_train, y_train)</span>
<span id="cb15-16"><a></a></span>
<span id="cb15-17"><a></a><span class="co"># Make new predictions</span></span>
<span id="cb15-18"><a></a>y_pred_best <span class="op">=</span> best_ridge.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best alpha: 0.1</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2">
<div id="7632495e" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a><span class="co"># Calculate R-squared</span></span>
<span id="cb17-2"><a></a>r2_best <span class="op">=</span> r2_score(y_test, y_pred_best)</span>
<span id="cb17-3"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared with best alpha: </span><span class="sc">{</span>r2_best<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-4"><a></a></span>
<span id="cb17-5"><a></a><span class="co"># Calculate Mean Squared Error (MSE)</span></span>
<span id="cb17-6"><a></a>mse_best <span class="op">=</span> mean_squared_error(y_test, y_pred_best)</span>
<span id="cb17-7"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error with best alpha: </span><span class="sc">{</span>mse_best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R-squared with best alpha: 0.8002247655359724
Mean Squared Error with best alpha: 1526.6464586641102</code></pre>
</div>
</div>
</div>
<div id="tabset-4-3">
<div id="fb206357" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a><span class="co"># Assuming `y_pred` are the predictions from the initial Ridge model</span></span>
<span id="cb19-2"><a></a>mse_initial <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb19-3"><a></a>r2_initial <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb19-4"><a></a></span>
<span id="cb19-5"><a></a><span class="co"># Print comparison</span></span>
<span id="cb19-6"><a></a><span class="bu">print</span>(<span class="ss">f'Initial MSE: </span><span class="sc">{</span>mse_initial<span class="sc">}</span><span class="ss">, Best Alpha MSE: </span><span class="sc">{</span>mse_best<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-7"><a></a><span class="bu">print</span>(<span class="ss">f'Initial R-squared: </span><span class="sc">{</span>r2_initial<span class="sc">}</span><span class="ss">, Best Alpha R-squared: </span><span class="sc">{</span>r2_best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial MSE: 1526.7075294439708, Best Alpha MSE: 1526.6464586641102
Initial R-squared: 0.8002167738825702, Best Alpha R-squared: 0.8002247655359724</code></pre>
</div>
</div>
</div>
<div id="tabset-4-4">
<div id="8a69f2f8" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a>residuals_best <span class="op">=</span> y_test <span class="op">-</span> y_pred_best</span>
<span id="cb21-2"><a></a>plt.scatter(y_pred_best, residuals_best, alpha <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb21-3"><a></a>plt.axhline(y <span class="op">=</span> <span class="dv">0</span>, color <span class="op">=</span> <span class="st">'r'</span>, linestyle <span class="op">=</span> <span class="st">'--'</span>)</span>
<span id="cb21-4"><a></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb21-5"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb21-6"><a></a>plt.title(<span class="st">'Residuals Plot with Best Alpha'</span>)</span>
<span id="cb21-7"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-14-output-1.png" width="829" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="lasso-regression" class="slide level2 smaller">
<h2>Lasso regression</h2>
<div class="panel-tabset">
<ul id="tabset-5" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-5-1">Visual</a></li><li><a href="#tabset-5-2">Formula</a></li><li><a href="#tabset-5-3">Key points</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1">
<div class="columns">
<div class="column" style="width:65%;">
<p><img data-src="images/lasso-1.png"></p>
</div><div class="column" style="width:35%;">
<p><br></p>
<p><img data-src="images/lasso-2.png" width="242"></p>
</div></div>
</div>
<div id="tabset-5-2">
<p><span class="math inline">\(RSS + \lambda \sum_{j=1}^{p} |\beta_j|\)</span></p>
<ul>
<li class="fragment"><p>Where <span class="math inline">\(j\)</span> ranges from 1 to <span class="math inline">\(p\)</span> and <span class="math inline">\(\lambda \geq 0\)</span></p></li>
<li class="fragment"><p><span class="math inline">\(\sum_{j=1}^{p} |\beta_j|\)</span> is the L1 normalization term</p></li>
</ul>
</div>
<div id="tabset-5-3">
<ul>
<li class="fragment"><p><strong>Penalized Regression</strong>: Implements OLS with an added L1 penalty on coefficients’ absolute values to reduce complexity and tackle multicollinearity.</p></li>
<li class="fragment"><p><strong>Feature Selection</strong>: Effectively zeroes out less significant coefficients, offering built-in feature selection for model simplicity.</p></li>
<li class="fragment"><p><strong>L1 Regularization</strong>: Uses <span class="math inline">\(\sum_{j=1}^{p} |\beta_j|\)</span> as the penalty, with <span class="math inline">\(λ\)</span> tuning the penalty’s strength.</p></li>
<li class="fragment"><p><strong>Bias-Variance</strong>: Increases bias to lower variance, aiding in overfitting prevention.</p></li>
<li class="fragment"><p><strong>Computation</strong>: May require iterative optimization, lacking a closed-form solution, especially in high-dimensional datasets.</p></li>
<li class="fragment"><p><strong>Sparse Solutions</strong>: Ideal for models expecting many non-influential features, providing sparsity.</p></li>
<li class="fragment"><p><strong>Interpretability</strong>: Enhances model interpretability by retaining only relevant features.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="lasso-regression-applied" class="slide level2 smaller">
<h2>Lasso regression: applied</h2>
<div class="panel-tabset">
<ul id="tabset-6" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-6-1">Model summary</a></li><li><a href="#tabset-6-2">Residual plot</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1">
<div id="5e5f2697" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a><span class="co"># Prepare the data (assuming X and y are already defined)</span></span>
<span id="cb22-2"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb22-3"><a></a></span>
<span id="cb22-4"><a></a><span class="co"># Initialize the Lasso Regression model</span></span>
<span id="cb22-5"><a></a>lasso_reg <span class="op">=</span> Lasso(alpha <span class="op">=</span> <span class="fl">1.0</span>)  <span class="co"># Alpha is the regularization strength; adjust accordingly</span></span>
<span id="cb22-6"><a></a></span>
<span id="cb22-7"><a></a><span class="co"># Fit the model</span></span>
<span id="cb22-8"><a></a>lasso_reg.fit(X_train, y_train)</span>
<span id="cb22-9"><a></a></span>
<span id="cb22-10"><a></a><span class="co"># Predict on the testing set</span></span>
<span id="cb22-11"><a></a>y_pred <span class="op">=</span> lasso_reg.predict(X_test)</span>
<span id="cb22-12"><a></a></span>
<span id="cb22-13"><a></a><span class="co"># Calculate and print the MSE</span></span>
<span id="cb22-14"><a></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb22-15"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-16"><a></a></span>
<span id="cb22-17"><a></a><span class="co"># Since Lasso doesn't provide AIC, BIC directly, we focus on what's available</span></span>
<span id="cb22-18"><a></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb22-19"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared: </span><span class="sc">{</span>r2<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 1535.3995053262377
R-squared: 0.7990793517178111</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2">
<div id="f335f658" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_pred</span>
<span id="cb24-2"><a></a>sns.residplot(x <span class="op">=</span> y_pred, y <span class="op">=</span> residuals, lowess <span class="op">=</span> <span class="va">True</span>, line_kws <span class="op">=</span> {<span class="st">'color'</span>: <span class="st">'red'</span>, <span class="st">'lw'</span>: <span class="dv">1</span>})</span>
<span id="cb24-3"><a></a>plt.xlabel(<span class="st">'Predicted Values'</span>)</span>
<span id="cb24-4"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb24-5"><a></a>plt.title(<span class="st">'Residual Plot for Lasso Regression'</span>)</span>
<span id="cb24-6"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-16-output-1.png" width="839" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="model-tuning-lasso-regression" class="slide level2 smaller">
<h2>Model tuning: Lasso regression</h2>
<div class="panel-tabset">
<ul id="tabset-7" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-7-1">Applied</a></li><li><a href="#tabset-7-2">Re-evaluate model</a></li><li><a href="#tabset-7-3">Compare with previous model</a></li><li><a href="#tabset-7-4">Residuals</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1">
<div id="478d2dda" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a></a><span class="co"># Define a range of alpha values for Lasso</span></span>
<span id="cb25-2"><a></a>alphas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">13</span>)</span>
<span id="cb25-3"><a></a></span>
<span id="cb25-4"><a></a><span class="co"># Initialize LassoCV</span></span>
<span id="cb25-5"><a></a>lasso_cv <span class="op">=</span> LassoCV(alphas <span class="op">=</span> alphas, cv <span class="op">=</span> <span class="dv">5</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb25-6"><a></a></span>
<span id="cb25-7"><a></a><span class="co"># Fit the model</span></span>
<span id="cb25-8"><a></a>lasso_cv.fit(X_train, y_train)</span>
<span id="cb25-9"><a></a></span>
<span id="cb25-10"><a></a><span class="co"># Optimal alpha value</span></span>
<span id="cb25-11"><a></a><span class="bu">print</span>(<span class="ss">f'Optimal alpha: </span><span class="sc">{</span>lasso_cv<span class="sc">.</span>alpha_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb25-12"><a></a></span>
<span id="cb25-13"><a></a><span class="co"># Re-initialize and fit the model with the optimal alpha</span></span>
<span id="cb25-14"><a></a>best_lasso <span class="op">=</span> Lasso(alpha <span class="op">=</span> lasso_cv.alpha_)</span>
<span id="cb25-15"><a></a>best_lasso.fit(X_train, y_train)</span>
<span id="cb25-16"><a></a></span>
<span id="cb25-17"><a></a><span class="co"># Make new predictions</span></span>
<span id="cb25-18"><a></a>y_pred_best <span class="op">=</span> best_lasso.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal alpha: 1e-06</code></pre>
</div>
</div>
</div>
<div id="tabset-7-2">
<div id="d12eaf40" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a></a><span class="co"># Calculate R-squared with the best alpha</span></span>
<span id="cb27-2"><a></a>r2_best <span class="op">=</span> r2_score(y_test, y_pred_best)</span>
<span id="cb27-3"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared with optimal alpha: </span><span class="sc">{</span>r2_best<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb27-4"><a></a></span>
<span id="cb27-5"><a></a><span class="co"># Calculate Mean Squared Error (MSE) with the best alpha</span></span>
<span id="cb27-6"><a></a>mse_best <span class="op">=</span> mean_squared_error(y_test, y_pred_best)</span>
<span id="cb27-7"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error with optimal alpha: </span><span class="sc">{</span>mse_best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R-squared with optimal alpha: 0.8002256319833501
Mean Squared Error with optimal alpha: 1526.6398374288794</code></pre>
</div>
</div>
</div>
<div id="tabset-7-3">
<div id="5b5e6863" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a><span class="co"># Assuming `y_pred` are the predictions from the initial Lasso model</span></span>
<span id="cb29-2"><a></a>mse_initial <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb29-3"><a></a>r2_initial <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb29-4"><a></a></span>
<span id="cb29-5"><a></a><span class="co"># Print comparison</span></span>
<span id="cb29-6"><a></a><span class="bu">print</span>(<span class="ss">f'Initial MSE: </span><span class="sc">{</span>mse_initial<span class="sc">}</span><span class="ss">, Optimal Alpha MSE: </span><span class="sc">{</span>mse_best<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-7"><a></a><span class="bu">print</span>(<span class="ss">f'Initial R-squared: </span><span class="sc">{</span>r2_initial<span class="sc">}</span><span class="ss">, Optimal Alpha R-squared: </span><span class="sc">{</span>r2_best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial MSE: 1535.3995053262377, Optimal Alpha MSE: 1526.6398374288794
Initial R-squared: 0.7990793517178111, Optimal Alpha R-squared: 0.8002256319833501</code></pre>
</div>
</div>
</div>
<div id="tabset-7-4">
<div id="a6342963" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a></a>residuals_best <span class="op">=</span> y_test <span class="op">-</span> y_pred_best</span>
<span id="cb31-2"><a></a>plt.scatter(y_pred_best, residuals_best, alpha <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb31-3"><a></a>plt.axhline(y <span class="op">=</span> <span class="dv">0</span>, color <span class="op">=</span> <span class="st">'r'</span>, linestyle <span class="op">=</span> <span class="st">'--'</span>)</span>
<span id="cb31-4"><a></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb31-5"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb31-6"><a></a>plt.title(<span class="st">'Residuals Plot with Optimal Alpha'</span>)</span>
<span id="cb31-7"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-20-output-1.png" width="829" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="elastic-net-regression" class="slide level2 smaller">
<h2>Elastic net regression</h2>
<div class="panel-tabset">
<ul id="tabset-8" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-8-1">Visual</a></li><li><a href="#tabset-8-2">Formula</a></li><li><a href="#tabset-8-3">Key points</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1">
<div class="columns">
<div class="column" style="width:65%;">
<p><img data-src="images/elastic-1.png"></p>
</div><div class="column" style="width:35%;">
<p><br></p>
<p><img data-src="images/elastic-2.png" width="242"></p>
</div></div>
</div>
<div id="tabset-8-2">
<p><span class="math inline">\(RSS + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2\)</span></p>
<ul>
<li class="fragment"><p>Where <span class="math inline">\(j\)</span> ranges from 1 to <span class="math inline">\(p\)</span> and <span class="math inline">\(\lambda \geq 0\)</span></p></li>
<li class="fragment"><p><span class="math inline">\(\sum_{j=1}^{p} |\beta_j|\)</span> is the L1 normalization term, which encourages sparsity in the coefficients</p></li>
<li class="fragment"><p><span class="math inline">\(\sum_{j=1}^{p} \beta_j^2\)</span> is the L2 normalization term, which encourages smoothness in the coefficients by penalizing large values.</p></li>
</ul>
</div>
<div id="tabset-8-3">
<ul>
<li class="fragment"><p><strong>Combines L1 and L2 Penalties</strong>: Merges Ridge and Lasso advantages for multicollinearity and feature selection.</p></li>
<li class="fragment"><p><strong>Optimizes Feature Selection</strong>: L1 part zeroes out insignificant coefficients; L2 part shrinks coefficients to manage multicollinearity.</p></li>
<li class="fragment"><p><strong>Requires Parameter Tuning</strong>: Optimal <span class="math inline">\(\lambda_1\)</span>​ and <span class="math inline">\(\lambda_2\)</span> balance feature elimination and coefficient reduction.</p></li>
<li class="fragment"><p><strong>Mitigates Overfitting</strong>: Adjusts bias-variance trade-off, reducing overfitting risk.</p></li>
<li class="fragment"><p><strong>Iterative Optimization</strong>: No closed-form solution due to L1 penalty; relies on optimization methods.</p></li>
<li class="fragment"><p><strong>Effective in High Dimensions</strong>: Suitable for datasets with more features than observations.</p></li>
<li class="fragment"><p><strong>Balances Sparsity and Stability</strong>: Ensures model relevance and stability through L1 and L2 penalties.</p></li>
<li class="fragment"><p><strong>Enhances Interpretability</strong>: Simplifies the model by keeping only relevant predictors, improving model interpretability.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="elastic-net-regression-applied" class="slide level2 smaller">
<h2>Elastic net regression: applied</h2>
<div class="panel-tabset">
<ul id="tabset-9" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-9-1">Model summary</a></li><li><a href="#tabset-9-2">Residual plot</a></li></ul>
<div class="tab-content">
<div id="tabset-9-1">
<div id="24949b52" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="co"># Assuming X and y are already defined and preprocessed</span></span>
<span id="cb32-2"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb32-3"><a></a></span>
<span id="cb32-4"><a></a><span class="co"># Initialize the Elastic Net Regression model with a mix of L1 and L2 regularization</span></span>
<span id="cb32-5"><a></a>elastic_net <span class="op">=</span> ElasticNet(alpha <span class="op">=</span> <span class="fl">1.0</span>, l1_ratio <span class="op">=</span> <span class="fl">0.5</span>)  <span class="co"># Adjust alpha and l1_ratio accordingly</span></span>
<span id="cb32-6"><a></a></span>
<span id="cb32-7"><a></a><span class="co"># Fit the model</span></span>
<span id="cb32-8"><a></a>elastic_net.fit(X_train, y_train)</span>
<span id="cb32-9"><a></a></span>
<span id="cb32-10"><a></a><span class="co"># Predict on the testing set</span></span>
<span id="cb32-11"><a></a>y_pred <span class="op">=</span> elastic_net.predict(X_test)</span>
<span id="cb32-12"><a></a></span>
<span id="cb32-13"><a></a><span class="co"># Calculate and print the MSE and R-squared</span></span>
<span id="cb32-14"><a></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb32-15"><a></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb32-16"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb32-17"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared: </span><span class="sc">{</span>r2<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 2258.2143010254194
R-squared: 0.7044926224424362</code></pre>
</div>
</div>
</div>
<div id="tabset-9-2">
<div id="dc9ec823" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_pred</span>
<span id="cb34-2"><a></a>sns.residplot(x <span class="op">=</span> y_pred, y <span class="op">=</span> residuals, lowess <span class="op">=</span> <span class="va">True</span>, line_kws <span class="op">=</span> {<span class="st">'color'</span>: <span class="st">'red'</span>, <span class="st">'lw'</span>: <span class="dv">1</span>})</span>
<span id="cb34-3"><a></a>plt.xlabel(<span class="st">'Predicted Values'</span>)</span>
<span id="cb34-4"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb34-5"><a></a>plt.title(<span class="st">'Residual Plot for Elastic Net Regression'</span>)</span>
<span id="cb34-6"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-22-output-1.png" width="829" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="model-tuning-elastic-net-regression" class="slide level2 smaller">
<h2>Model tuning: Elastic net regression</h2>
<div class="panel-tabset">
<ul id="tabset-10" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-10-1">Applied</a></li><li><a href="#tabset-10-2">Re-evaluate model</a></li><li><a href="#tabset-10-3">Compare with previous model</a></li><li><a href="#tabset-10-4">Residuals</a></li></ul>
<div class="tab-content">
<div id="tabset-10-1">
<div id="e544a763" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a></a><span class="co"># Define a range of alpha values and l1_ratios for Elastic Net</span></span>
<span id="cb35-2"><a></a>alphas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">13</span>)</span>
<span id="cb35-3"><a></a>l1_ratios <span class="op">=</span> np.linspace(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="dv">9</span>)</span>
<span id="cb35-4"><a></a></span>
<span id="cb35-5"><a></a><span class="co"># Initialize ElasticNetCV</span></span>
<span id="cb35-6"><a></a>elastic_net_cv <span class="op">=</span> ElasticNetCV(alphas <span class="op">=</span> alphas, l1_ratio <span class="op">=</span> l1_ratios, cv <span class="op">=</span> <span class="dv">5</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb35-7"><a></a></span>
<span id="cb35-8"><a></a><span class="co"># Fit the model to find the optimal alpha and l1_ratio</span></span>
<span id="cb35-9"><a></a>elastic_net_cv.fit(X_train, y_train)</span>
<span id="cb35-10"><a></a></span>
<span id="cb35-11"><a></a><span class="co"># Optimal alpha and l1_ratio</span></span>
<span id="cb35-12"><a></a><span class="bu">print</span>(<span class="ss">f'Optimal alpha: </span><span class="sc">{</span>elastic_net_cv<span class="sc">.</span>alpha_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb35-13"><a></a><span class="bu">print</span>(<span class="ss">f'Optimal l1_ratio: </span><span class="sc">{</span>elastic_net_cv<span class="sc">.</span>l1_ratio_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb35-14"><a></a></span>
<span id="cb35-15"><a></a><span class="co"># Re-initialize and fit the model with the optimal parameters</span></span>
<span id="cb35-16"><a></a>best_elastic_net <span class="op">=</span> ElasticNet(alpha<span class="op">=</span>elastic_net_cv.alpha_, l1_ratio<span class="op">=</span>elastic_net_cv.l1_ratio_)</span>
<span id="cb35-17"><a></a>best_elastic_net.fit(X_train, y_train)</span>
<span id="cb35-18"><a></a></span>
<span id="cb35-19"><a></a><span class="co"># Make new predictions</span></span>
<span id="cb35-20"><a></a>y_pred_best <span class="op">=</span> best_elastic_net.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal alpha: 0.0001
Optimal l1_ratio: 0.1</code></pre>
</div>
</div>
</div>
<div id="tabset-10-2">
<div id="af477e47" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a></a><span class="co"># Calculate R-squared with the best parameters</span></span>
<span id="cb37-2"><a></a>r2_best <span class="op">=</span> r2_score(y_test, y_pred_best)</span>
<span id="cb37-3"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared with optimal parameters: </span><span class="sc">{</span>r2_best<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb37-4"><a></a></span>
<span id="cb37-5"><a></a><span class="co"># Calculate Mean Squared Error (MSE) with the best parameters</span></span>
<span id="cb37-6"><a></a>mse_best <span class="op">=</span> mean_squared_error(y_test, y_pred_best)</span>
<span id="cb37-7"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error with optimal parameters: </span><span class="sc">{</span>mse_best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>R-squared with optimal parameters: 0.8002235829823968
Mean Squared Error with optimal parameters: 1526.6554955261286</code></pre>
</div>
</div>
</div>
<div id="tabset-10-3">
<div id="771f4dda" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a></a><span class="co"># Print comparison of MSE and R-squared before and after tuning</span></span>
<span id="cb39-2"><a></a>mse_initial <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb39-3"><a></a>r2_initial <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb39-4"><a></a><span class="bu">print</span>(<span class="ss">f'Initial MSE: </span><span class="sc">{</span>mse_initial<span class="sc">}</span><span class="ss">, Optimal Parameters MSE: </span><span class="sc">{</span>mse_best<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb39-5"><a></a><span class="bu">print</span>(<span class="ss">f'Initial R-squared: </span><span class="sc">{</span>r2_initial<span class="sc">}</span><span class="ss">, Optimal Parameters R-squared: </span><span class="sc">{</span>r2_best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial MSE: 2258.2143010254194, Optimal Parameters MSE: 1526.6554955261286
Initial R-squared: 0.7044926224424362, Optimal Parameters R-squared: 0.8002235829823968</code></pre>
</div>
</div>
</div>
<div id="tabset-10-4">
<div id="af676ecb" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a></a>residuals_best <span class="op">=</span> y_test <span class="op">-</span> y_pred_best</span>
<span id="cb41-2"><a></a>plt.scatter(y_pred_best, residuals_best, alpha <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb41-3"><a></a>plt.axhline(y <span class="op">=</span> <span class="dv">0</span>, color <span class="op">=</span> <span class="st">'r'</span>, linestyle <span class="op">=</span> <span class="st">'--'</span>)</span>
<span id="cb41-4"><a></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb41-5"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb41-6"><a></a>plt.title(<span class="st">'Residuals Plot with Optimal Parameters'</span>)</span>
<span id="cb41-7"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-26-output-1.png" width="829" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="summary-regularization" class="slide level2 smaller">
<h2>Summary: regularization</h2>
<ol type="1">
<li class="fragment"><p><strong>Reduces Overfitting</strong>: Regularization (Ridge, Lasso, Elastic Net) constrains model complexity, preventing overfitting by penalizing large coefficients.</p></li>
<li class="fragment"><p><strong>Parameter Optimization via CV</strong>: Cross-validation determines the optimal regularization strength (λ), ensuring model generalizability.</p></li>
<li class="fragment"><p><strong>Feature Selection with Lasso</strong>: Lasso (L1 penalty) zeroes out less significant coefficients, enabling automatic feature selection.</p></li>
<li class="fragment"><p><strong>Ridge Tackles Multicollinearity</strong>: Ridge regression (L2 penalty) minimizes collinearity effects among predictors by evenly shrinking coefficients.</p></li>
<li class="fragment"><p><strong>Elastic Net Merges Penalties</strong>: Elastic Net combines L1 and L2 penalties, ideal for correlated features and <u>high-dimensional data</u>, with CV tuning for optimal balance.</p></li>
<li class="fragment"><p><strong>CV Enhances Model Accuracy</strong>: Cross-validation across multiple folds improves accuracy and reliability of the chosen regularization parameter.</p></li>
<li class="fragment"><p><strong>Supports Sparse Solutions</strong>: Lasso and Elastic Net support sparse solutions, effectively reducing model complexity by selecting only relevant features.</p></li>
<li class="fragment"><p><strong>Bias-Variance Trade-off</strong>: Regularization adjusts the bias-variance trade-off, slightly increasing bias but significantly reducing variance.</p></li>
</ol>
</section></section>
<section>
<section id="high-dimensionality" class="title-slide slide level1 center">
<h1>High dimensionality</h1>

</section>
<section id="dimensional-reduction-revisited" class="slide level2">
<h2>Dimensional reduction: revisited</h2>
<blockquote>
<p>Dimension reduction techniques reduce the number of input variables in a dataset. In regression, these methods can help mitigate issues related to multicollinearity, overfitting, and the curse of dimensionality, particularly in high-dimensional data.</p>
</blockquote>
<div class="fragment">
<h3 id="two-main-methods">Two main methods:</h3>
<ol type="1">
<li class="fragment"><strong>Principal components regression (PCR)</strong></li>
<li class="fragment"><strong>Partial least squares (PLS)</strong></li>
</ol>
</div>
</section>
<section id="principal-components-regression-pcr" class="slide level2 smaller">
<h2>Principal components regression (PCR)</h2>
<div class="panel-tabset">
<ul id="tabset-11" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-11-1">Visual</a></li><li><a href="#tabset-11-2">Formula</a></li><li><a href="#tabset-11-3">Key points</a></li></ul>
<div class="tab-content">
<div id="tabset-11-1">
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/pcr-1.png" class="quarto-figure quarto-figure-center" width="336"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/pcr-3.png" class="quarto-figure quarto-figure-center" width="342"></p>
</figure>
</div>
</div></div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/pcr-2.png" class="quarto-figure quarto-figure-center" width="785"></p>
</figure>
</div>
</div>
<div id="tabset-11-2">
<blockquote>
<p>PCR involves two major steps—Principal Component Analysis (PCA) for dimensionality reduction, followed by regression on these principal components.</p>
</blockquote>
<ol type="1">
<li class="fragment"><p><strong>PCA Transformation</strong></p>
<p><span class="math inline">\(Z=XW\)</span></p>
<p>Where <span class="math inline">\(X\)</span> is the original dataset, <span class="math inline">\(W\)</span> represents the weight matrix for PCA, and <span class="math inline">\(Z\)</span> contains the principal components (PCs).</p></li>
<li class="fragment"><p><strong>Regression on PCs</strong></p>
<p><span class="math inline">\(\hat{Y} = ZB + \epsilon\)</span></p>
<p>Where <span class="math inline">\(\hat{Y}\)</span> is the predicted outcome, <span class="math inline">\(Z\)</span> are the PC predictors, <span class="math inline">\(B\)</span> is the coefficient matrix, <span class="math inline">\(\epsilon\)</span> is the error term</p></li>
</ol>
</div>
<div id="tabset-11-3">
<ol type="1">
<li class="fragment"><p><strong>Dimensionality Reduction</strong>: Transforms predictors into fewer uncorrelated principal components.</p></li>
<li class="fragment"><p><strong>Overcomes Multicollinearity</strong>: Uses orthogonal components, mitigating multicollinearity in the original predictors.</p></li>
<li class="fragment"><p><strong>Extracts Informative Features</strong>: Captures most data variance through principal components, enhancing model efficiency.</p></li>
<li class="fragment"><p><strong>Challenging Interpretation</strong>: Coefficients relate to principal components, complicating interpretation relative to original predictors.</p></li>
<li class="fragment"><p><strong>Critical Component Selection</strong>: Involves choosing the optimal number of components based on variance explained or cross-validation.</p></li>
<li class="fragment"><p><strong>Requires Standardization</strong>: PCA step necessitates variable scaling to ensure consistent variance across features.</p></li>
<li class="fragment"><p><strong>No Direct Feature Elimination</strong>: While reducing dimensions, PCR retains linear combinations of all features, unlike methods that select individual variables.</p></li>
</ol>
</div>
</div>
</div>
</section>
<section id="principal-components-regression-applied" class="slide level2 smaller">
<h2>Principal components regression: applied</h2>
<div class="panel-tabset">
<ul id="tabset-12" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-12-1">Model summary</a></li><li><a href="#tabset-12-2">Residual plot</a></li></ul>
<div class="tab-content">
<div id="tabset-12-1">
<div id="b8da0e8b" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a></a><span class="co"># Assuming X and y are already defined</span></span>
<span id="cb42-2"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb42-3"><a></a></span>
<span id="cb42-4"><a></a><span class="co"># Standardizing the features</span></span>
<span id="cb42-5"><a></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb42-6"><a></a></span>
<span id="cb42-7"><a></a><span class="co"># PCA for dimensionality reduction</span></span>
<span id="cb42-8"><a></a>pca <span class="op">=</span> PCA()</span>
<span id="cb42-9"><a></a></span>
<span id="cb42-10"><a></a><span class="co"># Linear Regression</span></span>
<span id="cb42-11"><a></a>lin_reg <span class="op">=</span> LinearRegression()</span>
<span id="cb42-12"><a></a></span>
<span id="cb42-13"><a></a><span class="co"># Creating a pipeline for PCR</span></span>
<span id="cb42-14"><a></a>pipeline <span class="op">=</span> Pipeline([(<span class="st">'scaler'</span>, scaler), (<span class="st">'pca'</span>, pca), (<span class="st">'lin_reg'</span>, lin_reg)])</span>
<span id="cb42-15"><a></a></span>
<span id="cb42-16"><a></a><span class="co"># Fit the PCR model</span></span>
<span id="cb42-17"><a></a>pipeline.fit(X_train, y_train)</span>
<span id="cb42-18"><a></a></span>
<span id="cb42-19"><a></a><span class="co"># Predict on the testing set</span></span>
<span id="cb42-20"><a></a>y_pred <span class="op">=</span> pipeline.predict(X_test)</span>
<span id="cb42-21"><a></a></span>
<span id="cb42-22"><a></a><span class="co"># Evaluate the model</span></span>
<span id="cb42-23"><a></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb42-24"><a></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb42-25"><a></a></span>
<span id="cb42-26"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb42-27"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared: </span><span class="sc">{</span>r2<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 1526.639833212853
R-squared: 0.8002256325350545</code></pre>
</div>
</div>
</div>
<div id="tabset-12-2">
<div id="46752a0c" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_pred</span>
<span id="cb44-2"><a></a>sns.residplot(x <span class="op">=</span> y_pred, y <span class="op">=</span> residuals, lowess <span class="op">=</span> <span class="va">True</span>, line_kws <span class="op">=</span> {<span class="st">'color'</span>: <span class="st">'red'</span>, <span class="st">'lw'</span>: <span class="dv">1</span>})</span>
<span id="cb44-3"><a></a>plt.xlabel(<span class="st">'Predicted Values'</span>)</span>
<span id="cb44-4"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb44-5"><a></a>plt.title(<span class="st">'Residual Plot for PCR'</span>)</span>
<span id="cb44-6"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-28-output-1.png" width="831" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="model-tuning-pcr" class="slide level2 smaller">
<h2>Model tuning: PCR</h2>
<div class="panel-tabset">
<ul id="tabset-13" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-13-1">Applied</a></li><li><a href="#tabset-13-2">Compare with previous model</a></li><li><a href="#tabset-13-3">Residuals</a></li></ul>
<div class="tab-content">
<div id="tabset-13-1">
<div id="e798f084" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a></a><span class="co"># Function to calculate MSE with cross-validation</span></span>
<span id="cb45-2"><a></a><span class="kw">def</span> cv_mse(n_components):</span>
<span id="cb45-3"><a></a>    pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb45-4"><a></a>        (<span class="st">'scaler'</span>, StandardScaler()), </span>
<span id="cb45-5"><a></a>        (<span class="st">'pca'</span>, PCA(n_components <span class="op">=</span> n_components)), </span>
<span id="cb45-6"><a></a>        (<span class="st">'lin_reg'</span>, LinearRegression())</span>
<span id="cb45-7"><a></a>    ])</span>
<span id="cb45-8"><a></a>    mse <span class="op">=</span> <span class="op">-</span>cross_val_score(pipeline, X_train, y_train, scoring <span class="op">=</span> <span class="st">'neg_mean_squared_error'</span>, cv <span class="op">=</span> <span class="dv">5</span>).mean()</span>
<span id="cb45-9"><a></a>    <span class="cf">return</span> mse</span>
<span id="cb45-10"><a></a></span>
<span id="cb45-11"><a></a><span class="co"># Testing different numbers of components</span></span>
<span id="cb45-12"><a></a>components_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">min</span>(<span class="bu">len</span>(X_train.columns), <span class="bu">len</span>(X_train)) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb45-13"><a></a>mse_scores <span class="op">=</span> [cv_mse(n) <span class="cf">for</span> n <span class="kw">in</span> components_range]</span>
<span id="cb45-14"><a></a></span>
<span id="cb45-15"><a></a><span class="co"># Find the optimal number of components</span></span>
<span id="cb45-16"><a></a>optimal_components <span class="op">=</span> components_range[np.argmin(mse_scores)]</span>
<span id="cb45-17"><a></a><span class="bu">print</span>(<span class="ss">f'Optimal number of components: </span><span class="sc">{</span>optimal_components<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb45-18"><a></a></span>
<span id="cb45-19"><a></a><span class="co"># Re-fit the PCR model with the optimal number of components</span></span>
<span id="cb45-20"><a></a>pipeline.set_params(pca__n_components <span class="op">=</span> optimal_components)</span>
<span id="cb45-21"><a></a>pipeline.fit(X_train, y_train)</span>
<span id="cb45-22"><a></a></span>
<span id="cb45-23"><a></a><span class="co"># New predictions and evaluation</span></span>
<span id="cb45-24"><a></a>y_pred_opt <span class="op">=</span> pipeline.predict(X_test)</span>
<span id="cb45-25"><a></a>mse_opt <span class="op">=</span> mean_squared_error(y_test, y_pred_opt)</span>
<span id="cb45-26"><a></a>r2_opt <span class="op">=</span> r2_score(y_test, y_pred_opt)</span>
<span id="cb45-27"><a></a></span>
<span id="cb45-28"><a></a><span class="bu">print</span>(<span class="ss">f'Optimized Mean Squared Error: </span><span class="sc">{</span>mse_opt<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb45-29"><a></a><span class="bu">print</span>(<span class="ss">f'Optimized R-squared: </span><span class="sc">{</span>r2_opt<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal number of components: 4
Optimized Mean Squared Error: 1526.639833212853
Optimized R-squared: 0.8002256325350545</code></pre>
</div>
</div>
</div>
<div id="tabset-13-2">
<div id="c16d3064" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a></a><span class="co"># Comparing initial and optimized model performances</span></span>
<span id="cb47-2"><a></a><span class="bu">print</span>(<span class="ss">f'Initial vs. Optimized MSE: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss"> vs. </span><span class="sc">{</span>mse_opt<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb47-3"><a></a><span class="bu">print</span>(<span class="ss">f'Initial vs. Optimized R-squared: </span><span class="sc">{</span>r2<span class="sc">}</span><span class="ss"> vs. </span><span class="sc">{</span>r2_opt<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial vs. Optimized MSE: 1526.639833212853 vs. 1526.639833212853
Initial vs. Optimized R-squared: 0.8002256325350545 vs. 0.8002256325350545</code></pre>
</div>
</div>
</div>
<div id="tabset-13-3">
<div id="26bb7e40" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a></a>residuals_opt <span class="op">=</span> y_test <span class="op">-</span> y_pred_opt</span>
<span id="cb49-2"><a></a>sns.residplot(x <span class="op">=</span> y_pred_opt, y <span class="op">=</span> residuals_opt, lowess <span class="op">=</span> <span class="va">True</span>, line_kws <span class="op">=</span> {<span class="st">'color'</span>: <span class="st">'red'</span>, <span class="st">'lw'</span>: <span class="dv">1</span>})</span>
<span id="cb49-3"><a></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb49-4"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb49-5"><a></a>plt.title(<span class="st">'Optimized Residual Plot for PCR'</span>)</span>
<span id="cb49-6"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-31-output-1.png" width="831" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="partial-least-squares-regression-pls" class="slide level2 smaller">
<h2>Partial least squares regression (PLS)</h2>
<div class="panel-tabset">
<ul id="tabset-14" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-14-1">Visual</a></li><li><a href="#tabset-14-2">Formula</a></li><li><a href="#tabset-14-3">Key points</a></li></ul>
<div class="tab-content">
<div id="tabset-14-1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/pls-1.png" class="quarto-figure quarto-figure-center" width="551"></p>
</figure>
</div>
</div>
<div id="tabset-14-2">
<blockquote>
<p>PLS focuses on predicting response variables by finding the linear regression model in a transformed space. It differs from PCR by considering the response variable <span class="math inline">\(Y\)</span> when determining the new feature space.</p>
</blockquote>
<ol type="1">
<li class="fragment"><p><strong>PLS Transformation</strong></p>
<p><span class="math inline">\(T=XW^{*}\)</span></p>
<p>Where <span class="math inline">\(X\)</span> is the original dataset, <span class="math inline">\(W^{*}\)</span> represents the weight matrix for PLS, and <span class="math inline">\(T\)</span> represents the scores (latent variables).</p></li>
<li class="fragment"><p><strong>Regression on PCs</strong></p>
<p><span class="math inline">\(\hat{Y} = TB + \epsilon\)</span></p>
<p>Where <span class="math inline">\(T\)</span> are the PLS latent variables (predictors), <span class="math inline">\(B\)</span> is the coefficient matrix, <span class="math inline">\(\epsilon\)</span> is the error term</p></li>
</ol>
</div>
<div id="tabset-14-3">
<ol type="1">
<li class="fragment"><p><strong>Dimensionality Reduction and Prediction</strong>: Reduces predictor dimensions while considering response variable <span class="math inline">\(Y\)</span>, optimizing for predictive power.</p></li>
<li class="fragment"><p><strong>Handles Multicollinearity</strong>: By generating latent variables, PLS mitigates multicollinearity, similar to PCR but with a focus on prediction.</p></li>
<li class="fragment"><p><strong>Incorporates Response in Feature Extraction</strong>: Unlike PCR, PLS extracts features based on their covariance with <span class="math inline">\(Y\)</span>, enhancing relevant feature capture.</p></li>
<li class="fragment"><p><strong>Component Selection is Crucial</strong>: The number of latent variables (components) is key to model performance, typically determined via cross-validation.</p></li>
<li class="fragment"><p><strong>Standardization May Be Necessary</strong>: Just like PCR, variable scaling can be important depending on the data characteristics.</p></li>
<li class="fragment"><p><strong>Suitable for High-Dimensional Data</strong>: Effective in scenarios where predictors far exceed observations.</p></li>
<li class="fragment"><p><strong>Direct Interpretation Challenging</strong>: Coefficients apply to latent variables, complicating direct interpretation relative to original predictors.</p></li>
</ol>
</div>
</div>
</div>
</section>
<section id="parial-least-squares-regression-applied" class="slide level2 smaller">
<h2>Parial least squares regression: applied</h2>
<div class="panel-tabset">
<ul id="tabset-15" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-15-1">Model summary</a></li><li><a href="#tabset-15-2">Residual plot</a></li></ul>
<div class="tab-content">
<div id="tabset-15-1">
<div id="5dc5ef3d" class="cell" data-execution_count="31">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a></a><span class="co"># Assuming X and y are already defined</span></span>
<span id="cb50-2"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb50-3"><a></a></span>
<span id="cb50-4"><a></a><span class="co"># Initialize PLS Regression model</span></span>
<span id="cb50-5"><a></a>pls <span class="op">=</span> PLSRegression(n_components <span class="op">=</span> <span class="dv">2</span>)  <span class="co"># Adjust n_components as needed</span></span>
<span id="cb50-6"><a></a></span>
<span id="cb50-7"><a></a><span class="co"># Fit the model</span></span>
<span id="cb50-8"><a></a>pls.fit(X_train, y_train)</span>
<span id="cb50-9"><a></a></span>
<span id="cb50-10"><a></a><span class="co"># Predict on the testing set</span></span>
<span id="cb50-11"><a></a>y_pred <span class="op">=</span> pls.predict(X_test)</span>
<span id="cb50-12"><a></a></span>
<span id="cb50-13"><a></a><span class="co"># Calculate and print the MSE and R-squared</span></span>
<span id="cb50-14"><a></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb50-15"><a></a>r2 <span class="op">=</span> r2_score(y_test, y_pred.flatten())  <span class="co"># Flatten if y_pred is 2D</span></span>
<span id="cb50-16"><a></a></span>
<span id="cb50-17"><a></a><span class="bu">print</span>(<span class="ss">f'Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb50-18"><a></a><span class="bu">print</span>(<span class="ss">f'R-squared: </span><span class="sc">{</span>r2<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 1534.9008172660479
R-squared: 0.7991446094751546</code></pre>
</div>
</div>
</div>
<div id="tabset-15-2">
<div id="a019d70c" class="cell" data-execution_count="32">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_pred.flatten()</span>
<span id="cb52-2"><a></a>sns.residplot(x <span class="op">=</span> y_pred.flatten(), y <span class="op">=</span> residuals, lowess <span class="op">=</span> <span class="va">True</span>, line_kws <span class="op">=</span> {<span class="st">'color'</span>: <span class="st">'red'</span>, <span class="st">'lw'</span>: <span class="dv">1</span>})</span>
<span id="cb52-3"><a></a>plt.xlabel(<span class="st">'Predicted Values'</span>)</span>
<span id="cb52-4"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb52-5"><a></a>plt.title(<span class="st">'Residual Plot for PLS Regression'</span>)</span>
<span id="cb52-6"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-33-output-1.png" width="837" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="model-tuning-pls" class="slide level2 smaller">
<h2>Model tuning: PLS</h2>
<div class="panel-tabset">
<ul id="tabset-16" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-16-1">Applied</a></li><li><a href="#tabset-16-2">Compare with previous model</a></li><li><a href="#tabset-16-3">Residuals</a></li></ul>
<div class="tab-content">
<div id="tabset-16-1">
<div id="12d06855" class="cell" data-execution_count="33">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a></a><span class="co"># Function to perform cross-validation and calculate MSE</span></span>
<span id="cb53-2"><a></a><span class="kw">def</span> cv_mse_pls(n_components):</span>
<span id="cb53-3"><a></a>    pls <span class="op">=</span> PLSRegression(n_components <span class="op">=</span> n_components)</span>
<span id="cb53-4"><a></a>    mse <span class="op">=</span> <span class="op">-</span>cross_val_score(pls, X_train, y_train, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, cv<span class="op">=</span><span class="dv">5</span>).mean()</span>
<span id="cb53-5"><a></a>    <span class="cf">return</span> mse</span>
<span id="cb53-6"><a></a></span>
<span id="cb53-7"><a></a><span class="co"># Determining the optimal number of components</span></span>
<span id="cb53-8"><a></a>components_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">min</span>(<span class="bu">len</span>(X_train.columns), <span class="bu">len</span>(X_train)) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb53-9"><a></a>mse_scores <span class="op">=</span> [cv_mse_pls(n) <span class="cf">for</span> n <span class="kw">in</span> components_range]</span>
<span id="cb53-10"><a></a></span>
<span id="cb53-11"><a></a><span class="co"># Optimal number of components</span></span>
<span id="cb53-12"><a></a>optimal_components <span class="op">=</span> components_range[np.argmin(mse_scores)]</span>
<span id="cb53-13"><a></a><span class="bu">print</span>(<span class="ss">f'Optimal number of components: </span><span class="sc">{</span>optimal_components<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb53-14"><a></a></span>
<span id="cb53-15"><a></a><span class="co"># Re-fit PLS model with the optimal number of components</span></span>
<span id="cb53-16"><a></a>pls.set_params(n_components <span class="op">=</span> optimal_components)</span>
<span id="cb53-17"><a></a>pls.fit(X_train, y_train)</span>
<span id="cb53-18"><a></a></span>
<span id="cb53-19"><a></a><span class="co"># New predictions and evaluation</span></span>
<span id="cb53-20"><a></a>y_pred_opt <span class="op">=</span> pls.predict(X_test)</span>
<span id="cb53-21"><a></a>mse_opt <span class="op">=</span> mean_squared_error(y_test, y_pred_opt)</span>
<span id="cb53-22"><a></a>r2_opt <span class="op">=</span> r2_score(y_test, y_pred_opt.flatten())</span>
<span id="cb53-23"><a></a></span>
<span id="cb53-24"><a></a><span class="bu">print</span>(<span class="ss">f'Optimized Mean Squared Error: </span><span class="sc">{</span>mse_opt<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb53-25"><a></a><span class="bu">print</span>(<span class="ss">f'Optimized R-squared: </span><span class="sc">{</span>r2_opt<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal number of components: 3
Optimized Mean Squared Error: 1526.5692627318958
Optimized R-squared: 0.8002348673086326</code></pre>
</div>
</div>
</div>
<div id="tabset-16-2">
<div id="b8c73ece" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a></a><span class="co"># Comparing initial and optimized model performances</span></span>
<span id="cb55-2"><a></a><span class="bu">print</span>(<span class="ss">f'Initial vs. Optimized MSE: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss"> vs. </span><span class="sc">{</span>mse_opt<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb55-3"><a></a><span class="bu">print</span>(<span class="ss">f'Initial vs. Optimized R-squared: </span><span class="sc">{</span>r2<span class="sc">}</span><span class="ss"> vs. </span><span class="sc">{</span>r2_opt<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial vs. Optimized MSE: 1534.9008172660479 vs. 1526.5692627318958
Initial vs. Optimized R-squared: 0.7991446094751546 vs. 0.8002348673086326</code></pre>
</div>
</div>
</div>
<div id="tabset-16-3">
<div id="815bc3aa" class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a></a>residuals_opt <span class="op">=</span> y_test <span class="op">-</span> y_pred_opt.flatten()</span>
<span id="cb57-2"><a></a>sns.residplot(x <span class="op">=</span> y_pred_opt.flatten(), y <span class="op">=</span> residuals_opt, lowess <span class="op">=</span> <span class="va">True</span>, line_kws <span class="op">=</span> {<span class="st">'color'</span>: <span class="st">'red'</span>, <span class="st">'lw'</span>: <span class="dv">1</span>})</span>
<span id="cb57-3"><a></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb57-4"><a></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb57-5"><a></a>plt.title(<span class="st">'Optimized Residual Plot for PLS Regression'</span>)</span>
<span id="cb57-6"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="08-regn-2_files/figure-revealjs/cell-36-output-1.png" width="831" height="455"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="considerations-in-high-dimensions" class="slide level2 smaller">
<h2>Considerations in high dimensions</h2>
<ul>
<li class="fragment"><p><strong>Overfitting in High-Dimensional Data</strong>: Models may capture noise as signal, leading to overfitting.</p></li>
<li class="fragment"><p><strong>Curse of Dimensionality</strong>: Increased dimensionality exponentially expands data space, causing data sparsity and learning difficulties.</p></li>
<li class="fragment"><p><strong>Multicollinearity Risks</strong>: More features increase the likelihood of correlated predictors, destabilizing models.</p></li>
<li class="fragment"><p><strong>Use of Regularization</strong>: Techniques like Lasso and Ridge effectively address high-dimensional challenges by shrinking coefficients and simplifying models.</p></li>
<li class="fragment"><p><strong>Model Simplification</strong>: PCR and PLS reduce variable count, aiding interpretability.</p></li>
<li class="fragment"><p><strong>Feature Importance Analysis</strong>: Identifying influential features becomes harder in high dimensions; Lasso’s feature selection is beneficial.</p></li>
<li class="fragment"><p><strong>Need for Dimensionality Reduction</strong>: Essential for crafting robust, interpretable models in high-dimensional scenarios.</p></li>
</ul>
</section>
<section id="conclusions" class="slide level2 smaller">
<h2>Conclusions</h2>
<div class="panel-tabset">
<ul id="tabset-17" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-17-1">Table</a></li><li><a href="#tabset-17-2">Note, why might best MSE and <span class="math inline">\(R^{2}\)</span> not match?</a></li></ul>
<div class="tab-content">
<div id="tabset-17-1">
<table class="caption-top">
<colgroup>
<col style="width: 68%">
<col style="width: 18%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>MSE</th>
<th><span class="math inline">\(R^{2}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Multiple regression (OLS, best fit)</strong></td>
<td>1526.64</td>
<td>0.8002</td>
</tr>
<tr class="even">
<td>Ridge regression (best <span class="math inline">\(\lambda\)</span>)</td>
<td>1526.646</td>
<td>0.8002</td>
</tr>
<tr class="odd">
<td>Lasso regression (best <span class="math inline">\(\alpha\)</span>)</td>
<td>1526.64</td>
<td>0.8002</td>
</tr>
<tr class="even">
<td>Elastic net (best <span class="math inline">\(\lambda, \alpha\)</span>)</td>
<td>1526.655</td>
<td>0.8002</td>
</tr>
<tr class="odd">
<td>Principle components (best # components)</td>
<td>1526.64</td>
<td>0.8002</td>
</tr>
<tr class="even">
<td><strong>Partial least squares (best # components)</strong></td>
<td><strong>1526.57</strong></td>
<td>0.8002</td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><strong>Occam’s Razor loses!</strong></p>
</div>
</div>
<div id="tabset-17-2">
<ul>
<li class="fragment"><p><strong>Simpler Models</strong>: A model with <strong>fewer predictors</strong> may achieve lower MSE without significantly improving explanation, resulting in lower Adjusted R-squared.</p></li>
<li class="fragment"><p><strong>Scale &amp; Variance</strong>: Models on <strong>low-variance data</strong> can show lower MSE but not necessarily higher Adjusted R-squared, reflecting prediction efficiency over variance explanation.</p></li>
<li class="fragment"><p><strong>Balance</strong>: <strong>Overfit models</strong> might have lower MSE but lower Adjusted R-squared, indicating poor generalization versus models that balance complexity and predictive power.</p></li>
<li class="fragment"><p><strong>Split Variability</strong>: <strong>Train-test split differences</strong> can affect MSE more than Adjusted R-squared, especially with test set anomalies.</p></li>
<li class="fragment"><p><strong>Error Patterns</strong>: Models with <strong>evenly distributed errors</strong> tend to have <strong>higher Adjusted R-squared</strong> <u>even if MSE is slightly higher</u>, compared to those with uneven error distribution.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="in-class-exercise" class="slide level2">
<h2>In-class Exercise</h2>
<div class="task">
<p>Go to <a href="https://datamineaz.org/exercises/ex-08.html">ex-08</a> and perform the tasks</p>
</div>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://datamineaz.org/">🔗 datamineaz.org</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>